### Sequence 2 Sequence Architecture ###

Simple sequence 2 sequence architecture using LSTM to sort characters. For eg. 'abfhjke' translates to 'abefhjk' as output. Just after few iterations, learns the sorting perfectly.

For the training data, create two files with features (features.txt), and corresponding targets (targets.txt) with input sequence (eg. 'ahgtr', 'bfjwer') and sorted sequence (eg. 'aghrt', 'befjrw')

Currently, working on extending this architecture (and of course use an embedding layer), to do language translation.
